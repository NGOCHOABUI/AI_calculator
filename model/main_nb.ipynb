{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HANDWRITTEN CALCULATOR\n",
    "\n",
    "On the first part of this Lab session, we are going to train a Machine Learning model to classify digits (0-9) and math operators (+, -, x, /).\n",
    "\n",
    "YOUR PART: BUILD THE MODEL, TRAIN AND EXPORT THE MODEL TO \".H5\" FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import shutil\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = pathlib.Path('/Users/nhanpham/CoderSchool/AI_calculator/complete_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_paths():\n",
    "    all_image_paths = [str(path) for path in list(data_root.glob(\"**/*\")) if path.is_file()]\n",
    "    random.shuffle(all_image_paths)\n",
    "    return all_image_paths, len(all_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_paths, image_count = load_image_paths()\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_image(path_list):\n",
    "    \"\"\" Check if image is readable and not DS_STORE file\n",
    "    \"\"\"\n",
    "    \n",
    "    for index, image_path in enumerate(path_list):\n",
    "        if (image_path.split('.')[1] != \"DS_Store\") :\n",
    "            try:\n",
    "                image = tf.io.read_file(image_path)\n",
    "                image = tf.image.decode_jpeg(image, channels=3)\n",
    "            except:\n",
    "                print(all_image_paths[index])\n",
    "            if index % 3000 == 0: \n",
    "                print(index)\n",
    "        else:\n",
    "            path_list.remove(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_image(all_image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels():\n",
    "    label_names = sorted(item.name for item in data_root.glob('**/') if item.is_dir())\n",
    "    return np.array(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = load_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# might have to remove unrelevant labels\n",
    "# label_names.remove('.ipynb_checkpoints')\n",
    "label_names = label_names[:-1].astype(int)\n",
    "label_names.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary for prediction index to real label\n",
    "label_to_index = dict((str(name), index) for index, name in enumerate(label_names))\n",
    "label_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get label of every images in the path list\n",
    "all_image_labels = [label_to_index[pathlib.Path(path).parent.name] for path in all_image_paths]\n",
    "\n",
    "# get the first 10 lables to check if the random shuffle actually work\n",
    "print(\"First 10 labels indices: \", all_image_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the amount of images in each class\n",
    "count = Counter()\n",
    "for label in all_image_labels:\n",
    "    count[label_names[label]] += 1\n",
    "    \n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPLITING DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_paths, test_image_paths, train_image_labels, test_image_labels = train_test_split(all_image_paths, all_image_labels, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_image_paths))\n",
    "print(len(test_image_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.image.resize(image, [28, 28])\n",
    "    image = (255 - image)/255.0\n",
    "\n",
    "    return image\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    return preprocess_image(image)\n",
    "\n",
    "def load_and_preprocess_from_path_label(path, label):\n",
    "    return load_and_preprocess_image(path), label\n",
    "\n",
    "def visualize_random():\n",
    "    index = random.randint(0, image_count)\n",
    "    image_path = all_image_paths[index]\n",
    "    label = all_image_labels[index]\n",
    "\n",
    "    # show image\n",
    "    print(image_path)\n",
    "    plt.imshow(load_and_preprocess_image(image_path)[:,:,0], cmap='gray')\n",
    "    plt.grid(False)\n",
    "    plt.title(label_names[label])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "def create_ds(all_image_paths, all_image_labels):\n",
    "    \"\"\" Load dataset into tensor\n",
    "    \"\"\"\n",
    "    ds = tf.data.Dataset.from_tensor_slices((all_image_paths, all_image_labels))\n",
    "    image_label_ds = ds.map(load_and_preprocess_from_path_label)\n",
    "    ds = image_label_ds.shuffle(buffer_size=image_count)\n",
    "    ds = ds.repeat().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = create_ds(train_image_paths, train_image_labels)\n",
    "test_set = create_ds(test_image_paths, test_image_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(learning_rate=0.01):  \n",
    "    model = tf.keras.Sequential([   \n",
    "          tf.keras.layers.Conv2D(kernel_size=3, filters=12, use_bias=False, padding='same', input_shape=(28, 28, 1)),\n",
    "          \n",
    "          #YOUR CODE HERE\n",
    "          ____________\n",
    "\n",
    "          tf.keras.layers.Dense(len(label_names), activation='softmax')\n",
    "    ])\n",
    "\n",
    "      #YOUR CODE HERE\n",
    "    model.compile(optimizer=_____,\n",
    "                  loss=______,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = build_model()\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Setting up Callbacks \n",
    "class CollectBatchStats(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.batch_losses = []\n",
    "        self.batch_acc = []\n",
    "        self.batch_val_losses = []\n",
    "        self.batch_val_acc = []\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.batch_losses.append(logs['loss'])\n",
    "        self.batch_acc.append(logs['accuracy'])\n",
    "\n",
    "    def on_test_batch_end(self, batch, logs=None):\n",
    "        self.batch_val_losses.append(logs['loss'])\n",
    "        self.batch_val_acc.append(logs['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = len(train_image_labels) // BATCH_SIZE\n",
    "val_steps_per_epoch = len(test_image_labels) // BATCH_SIZE\n",
    "batch_stats_callback = CollectBatchStats()\n",
    "\n",
    "# FIT THE DATA NOW\n",
    "history = cnn_model.fit(train_set, \n",
    "                        epochs=5, \n",
    "                        steps_per_epoch=steps_per_epoch,\n",
    "                        callbacks = [batch_stats_callback],\n",
    "                        validation_data=test_set,\n",
    "                        validation_steps=val_steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(training_losses, val_losses, x_label='Training Steps'):\n",
    "    plt.figure()\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(x_label)\n",
    "    \n",
    "    training_steps = len(training_losses)\n",
    "    test_steps = len(val_losses)\n",
    "    plt.plot(training_losses, label='Training Loss')\n",
    "    plt.plot(np.linspace(0, training_steps, test_steps), val_losses, label='Validation Loss')\n",
    "    plt.ylim([0,max(plt.ylim())])\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "def plot_accuracy(training_acc, val_acc, x_label='Training Steps'):\n",
    "    plt.figure()\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(x_label)\n",
    "    \n",
    "    training_steps = len(training_acc)\n",
    "    test_steps = len(val_acc)\n",
    "    plt.plot(training_acc, label='Training Accuracy')\n",
    "    plt.plot(np.linspace(0, training_steps, test_steps), val_acc, label='Validation Accuracy')\n",
    "    plt.ylim([0,1])\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_results(training_acc, val_acc, epoch_acc, epoch_val_acc):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(1, 2, figsize=[14, 5])\n",
    "\n",
    "    # Plot batchs training & validation accuracy\n",
    "    ax[0].set_ylabel(\"Accuracy\")\n",
    "    ax[0].set_xlabel(\"Training Steps\")\n",
    "\n",
    "    training_steps = len(training_acc)\n",
    "    test_steps = len(val_acc)\n",
    "    ax[0].plot(training_acc, label='Batch Training Accuracy')\n",
    "    ax[0].plot(np.linspace(0, training_steps, test_steps), val_acc, label='Batch Validation Accuracy')\n",
    "    ax[0].set_ylim([0.7,1])\n",
    "    ax[0].legend(loc='lower right')\n",
    "\n",
    "    # Plot epochs training & validation accuracy\n",
    "    ax[1].set_ylabel(\"Accuracy\")\n",
    "    ax[1].set_xlabel(\"Epochs\")\n",
    "\n",
    "    train_epochs = len(epoch_acc)\n",
    "    val_epochs = len(epoch_val_acc)\n",
    "    ax[1].plot(epoch_acc, label='Epoch Training Accuracy')\n",
    "    ax[1].plot(np.linspace(0, train_epochs, val_epochs), epoch_val_acc, label='Epoch Validation Accuracy')\n",
    "    ax[1].set_ylim([0.7,1])\n",
    "    ax[1].legend(loc='lower right')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_training_results(batch_stats_callback.batch_acc,      #batch stats\n",
    "                      batch_stats_callback.batch_val_acc,  #batch stats\n",
    "                      history.history['accuracy'],         #epoch stats\n",
    "                      history.history['val_accuracy']      #epoch stats\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take 1 batch out for testing\n",
    "for image_batch, label_batch in test_set:\n",
    "    print(\"Image batch shape: \", image_batch.shape)\n",
    "    print(\"Label batch shape: \", label_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "label_names = np.array(label_names)\n",
    "predicted_batch = cnn_model.predict(image_batch)\n",
    "predicted_id = np.argmax(predicted_batch, axis=1)\n",
    "predicted_label_batch = label_names[predicted_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the result\n",
    "plt.figure(figsize=(10,9))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "for n in range(30):\n",
    "    plt.subplot(6,5,n+1)\n",
    "    plt.imshow(image_batch[n][:,:,0])\n",
    "    color = \"green\" if predicted_id[n] == label_batch.numpy()[n] else \"red\"\n",
    "    plt.title(predicted_label_batch[n], color=color)\n",
    "    plt.axis('off')\n",
    "_ = plt.suptitle(\"Model predictions (green: correct, red: incorrect)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPORT MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.save('maths.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recheck loaded model\n",
    "\n",
    "reloaded_model = tf.keras.models.load_model('/Users/nhanpham/CoderSchool/AI_calculator/model/maths.h5')\n",
    "reloaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if the current model result and export model result is consistent\n",
    "result_batch = cnn_model.predict(image_batch)\n",
    "reloaded_result_batch = reloaded_model.predict(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is any difference\n",
    "abs(reloaded_result_batch - result_batch).max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}